services:
  # --- Init containers for volume permissions ---

  fix-input-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R 1000:1000 /input && chmod -R 775 /input"]
    volumes:
      - input:/input
    restart: "no"

  fix-queue-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R 1000:1000 /queue && chmod -R 775 /queue"]
    volumes:
      - queue:/queue
    restart: "no"

  fix-metadata-json-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R 1000:1000 /metadata/json && chmod -R 775 /metadata/json"]
    volumes:
      - metadata_json:/metadata/json
    restart: "no"

  fix-stems-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R 1000:1000 /stems && chmod -R 775 /stems"]
    volumes:
      - stems:/stems
    restart: "no"

  fix-output-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R 1000:1000 /output && chmod -R 775 /output"]
    volumes:
      - output:/output
    restart: "no"

  fix-organized-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R 1000:1000 /organized && chmod -R 775 /organized"]
    volumes:
      - organized:/organized
    restart: "no"

  fix-splitter-tmp-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R 1000:1000 /tmp && chmod -R 1777 /tmp"]
    volumes:
      - splitter_tmp:/tmp
    restart: "no"

  # --- Core pipeline services ---

  redis:
    image: redis:7-alpine
    container_name: karaoke_redis
    restart: unless-stopped

  watcher:
    build: ./watcher
    container_name: karaoke_watcher
    depends_on:
      - fix-input-permissions
      - fix-queue-permissions
      - redis
    volumes:
      - input:/input
      - queue:/queue
    environment:
      - REDIS_HOST=redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      retries: 3

  metadata:
    build: ./metadata
    container_name: karaoke_metadata
    depends_on:
      - fix-queue-permissions
      - fix-metadata-json-permissions
      - watcher
      - redis
    volumes:
      - queue:/queue
      - metadata_json:/metadata/json
    environment:
      - REDIS_HOST=redis
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      retries: 3

  splitter:
    build: ./splitter
    container_name: karaoke_splitter
    depends_on:
      - fix-queue-permissions
      - fix-stems-permissions
      - fix-splitter-tmp-permissions
      - metadata
      - redis
    volumes:
      - queue:/queue
      - stems:/stems
      - splitter_tmp:/tmp
      - ./models:/app/pretrained_models
    environment:
      - REDIS_HOST=redis
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    healthcheck:
      test: ["CMD", "bash", "-c", "exit 0"]
      interval: 30s
      retries: 3

  packager:
    build: ./packager
    container_name: karaoke_packager
    depends_on:
      - fix-stems-permissions
      - fix-metadata-json-permissions
      - fix-output-permissions
      - splitter
      - redis
    volumes:
      - stems:/stems
      - metadata_json:/metadata/json
      - output:/output
    environment:
      - REDIS_HOST=redis
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      retries: 3

  organizer:
    build: ./organizer
    container_name: karaoke_organizer
    depends_on:
      - fix-output-permissions
      - fix-organized-permissions
      - fix-metadata-json-permissions
      - packager
      - redis
    volumes:
      - output:/output
      - organized:/organized
      - metadata_json:/metadata/json
    environment:
      - REDIS_HOST=redis
      - OUTPUT_DIR=/output
      - ORG_DIR=/organized
      - LOGS_DIR=/logs
      - META_DIR=/metadata/json
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      retries: 3

  status-api:
    build: ./status-api
    container_name: karaoke_status_api
    depends_on:
      - fix-input-permissions
      - fix-queue-permissions
      - fix-metadata-json-permissions
      - fix-stems-permissions
      - fix-output-permissions
      - fix-organized-permissions
      - organizer
      - redis
    ports:
      - "5001:5001"
    volumes:
      - input:/input
      - queue:/queue
      - metadata_json:/metadata/json
      - stems:/stems
      - output:/output
      - organized:/organized
    environment:
      - REDIS_HOST=redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      retries: 3

  maintenance:
    build: ./maintenance
    container_name: karaoke_maintenance
    depends_on:
      - redis
    volumes:
      - metadata_json:/metadata/json
      - stems:/stems
      - output:/output
      - queue:/queue
      - organized:/organized
    environment:
      - REDIS_HOST=redis
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    entrypoint: ["python", "cleanup.py"]

  maintenance-cron:
    build: ./maintenance
    container_name: karaoke_maintenance_cron
    depends_on:
      - redis
    volumes:
    environment:
      - REDIS_HOST=redis
      # (Add any required ENV for notifications)
    restart: unless-stopped

  telegram_youtube_bot:
    build: ./telegram_youtube_bot
    container_name: telegram_youtube_bot
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
      - YTDLP_OUTPUT_DIR=/input
      - METADATA_OUTPUT_DIR=/metadata/json
    volumes:
      - input:/input
      - metadata_json:/metadata/json
    depends_on:
      - fix-input-permissions
      - fix-metadata-json-permissions
    restart: unless-stopped

  # --- Support and UI containers (unchanged from your file) ---

  tunnel:
    container_name: tunnel
    image: cloudflare/cloudflared:latest
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${TUNNEL_TOKEN}

  jellyfin:
    image: lscr.io/linuxserver/jellyfin:latest
    container_name: jellyfin
    environment:
      - PUID=1000
      - PGID=1000
      - TZ=America/New_York
      - JELLYFIN_PublishedServerUrl=http://http://172.28.221.43 #optional
    volumes:
      - ./jellyfin/library:/config
      - organized:/organized
    ports:
      - 8096:8096
      - 8920:8920 #optional
      - 7359:7359/udp #optional
      - 1900:1900/udp #optional
    restart: unless-stopped

  deemix:
    image: registry.gitlab.com/bockiii/deemix-docker
    container_name: deemix
    environment:
      - PUID=1000
      - PGID=1000
      - UMASK_SET=022
    volumes:
      - input:/downloads
      - ./deemix_config:/config
    ports:
      - 6595:6595
    restart: unless-stopped

  doublecommander:
    image: lscr.io/linuxserver/doublecommander:latest
    container_name: doublecommander
    environment:
      - PUID=1000
      - PGID=1000
    volumes:
      - input:/karaoke-mvp/input
      - output:/karaoke-mvp/output
      - stems:/karaoke-mvp/stems
      - queue:/karaoke-mvp/queue
      - metadata_json:/karaoke-mvp/metadata/json
      - organized:/karaoke-mvp/organized
      - ./models:/karaoke-mvp/models
      - splitter_tmp:/karaoke-mvp/splitter-tmp
      - ./doublecommander_config:/config
    ports:
      - 3000:3000
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - ./alert.rules.yml:/etc/prometheus/alert.rules.yml
    ports:
      - "9090:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    volumes:
      - ./grafana_data:/var/lib/grafana
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml
      - ./telegram.tmpl:/etc/alertmanager/telegram.tmpl
    ports:
      - "9093:9093"
    restart: unless-stopped

volumes:
  input:
  queue:
  metadata_json:
  stems:
  output:
  organized:
  splitter_tmp:
  shared_utils:
    driver: local
    driver_opts:
      type: none
      device: ./shared
      o: bind
