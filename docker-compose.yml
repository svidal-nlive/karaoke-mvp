version: "3.8"

services:
  # --- Permissions init jobs (run-once, do not restart) ---
  fix-input-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R ${PUID}:${PGID} /input && chmod -R 775 /input"]
    volumes: [input:/input]
    restart: "no"

  fix-queue-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R ${PUID}:${PGID} /queue && chmod -R 775 /queue"]
    volumes: [queue:/queue]
    restart: "no"

  fix-metadata-json-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R ${PUID}:${PGID} /metadata/json && chmod -R 775 /metadata/json"]
    volumes: [metadata_json:/metadata/json]
    restart: "no"

  fix-stems-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R ${PUID}:${PGID} /stems && chmod -R 775 /stems"]
    volumes: [stems:/stems]
    restart: "no"

  fix-output-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R ${PUID}:${PGID} /output && chmod -R 775 /output"]
    volumes: [output:/output]
    restart: "no"

  fix-organized-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R ${PUID}:${PGID} /organized && chmod -R 775 /organized"]
    volumes: [organized:/organized]
    restart: "no"

  fix-splitter-tmp-permissions:
    image: alpine:latest
    command: ["sh", "-c", "chown -R ${PUID}:${PGID} /tmp && chmod -R 1777 /tmp"]
    volumes: [splitter_tmp:/tmp]
    restart: "no"

  # --- Core pipeline services ---
  redis:
    image: redis:7-alpine
    container_name: karaoke_redis
    restart: unless-stopped
    ports:
      - "6379:6379"

  watcher:
    build:
      context: ./watcher
      dockerfile: Dockerfile
    container_name: karaoke_watcher
    depends_on:
      - fix-input-permissions
      - fix-queue-permissions
      - redis
    volumes:
      - input:/input
      - queue:/queue
      - shared_utils:/app/shared:ro
    environment:
      - REDIS_HOST=${REDIS_HOST}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      retries: 3

  metadata:
    build:
      context: ./metadata
      dockerfile: Dockerfile
    container_name: karaoke_metadata
    depends_on:
      - fix-queue-permissions
      - fix-metadata-json-permissions
      - watcher
      - redis
    volumes:
      - queue:/queue
      - metadata_json:/metadata/json
      - shared_utils:/app/shared:ro
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      retries: 3

  splitter:
    build:
      context: ./splitter
      dockerfile: Dockerfile
    container_name: karaoke_splitter
    depends_on:
      - fix-queue-permissions
      - fix-stems-permissions
      - fix-splitter-tmp-permissions
      - metadata
      - redis
    volumes:
      - queue:/queue
      - stems:/stems
      - splitter_tmp:/tmp
      - shared_utils:/app/shared:ro
      - ./models:/app/pretrained_models:ro
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    healthcheck:
      test: ["CMD", "bash", "-c", "exit 0"]
      interval: 30s
      retries: 3

  packager:
    build:
      context: ./packager
      dockerfile: Dockerfile
    container_name: karaoke_packager
    depends_on:
      - fix-stems-permissions
      - fix-metadata-json-permissions
      - fix-output-permissions
      - splitter
      - redis
    volumes:
      - stems:/stems
      - metadata_json:/metadata/json
      - output:/output
      - shared_utils:/app/shared:ro
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      retries: 3

  organizer:
    build:
      context: ./organizer
      dockerfile: Dockerfile
    container_name: karaoke_organizer
    depends_on:
      - fix-output-permissions
      - fix-organized-permissions
      - fix-metadata-json-permissions
      - packager
      - redis
    volumes:
      - output:/output
      - organized:/organized
      - metadata_json:/metadata/json
      - shared_utils:/app/shared:ro
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - OUTPUT_DIR=/output
      - ORG_DIR=/organized
      - LOGS_DIR=/logs
      - META_DIR=/metadata/json
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      retries: 3

  status-api:
    build:
      context: ./status-api
      dockerfile: Dockerfile
    container_name: karaoke_status_api
    depends_on:
      - fix-input-permissions
      - fix-queue-permissions
      - fix-metadata-json-permissions
      - fix-stems-permissions
      - fix-output-permissions
      - fix-organized-permissions
      - organizer
      - redis
    ports:
      - "5001:5001"
    volumes:
      - input:/input
      - queue:/queue
      - metadata_json:/metadata/json
      - stems:/stems
      - output:/output
      - organized:/organized
      - shared_utils:/app/shared:ro
    environment:
      - REDIS_HOST=${REDIS_HOST}
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: 30s
      retries: 3

  maintenance:
    build:
      context: ./maintenance
      dockerfile: Dockerfile
    container_name: karaoke_maintenance
    depends_on:
      - redis
    volumes:
      - metadata_json:/metadata/json
      - stems:/stems
      - output:/output
      - queue:/queue
      - organized:/organized
      - shared_utils:/app/shared:ro
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
    entrypoint: ["python", "cleanup.py"]

  maintenance-cron:
    build:
      context: ./maintenance
      dockerfile: Dockerfile
    container_name: karaoke_maintenance_cron
    depends_on:
      - redis
    volumes:
      - metadata_json:/metadata/json
      - stems:/stems
      - output:/output
      - queue:/queue
      - organized:/organized
      - shared_utils:/app/shared:ro
    environment:
      - REDIS_HOST=${REDIS_HOST}
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
      - CLEANUP_CRON_SCHEDULE=${CLEANUP_CRON_SCHEDULE}
    restart: unless-stopped
    command: ["sh", "-c", "crontab /app/crontab && cron -f"]

  telegram_youtube_bot:
    build:
      context: ./telegram_youtube_bot
      dockerfile: Dockerfile
    container_name: telegram_youtube_bot
    environment:
      - TELEGRAM_BOT_TOKEN=${TELEGRAM_BOT_TOKEN}
      - TELEGRAM_CHAT_ID=${TELEGRAM_CHAT_ID}
      - YTDLP_OUTPUT_DIR=/input
      - METADATA_OUTPUT_DIR=/metadata/json
    volumes:
      - input:/input
      - metadata_json:/metadata/json
    depends_on:
      - fix-input-permissions
      - fix-metadata-json-permissions
    restart: unless-stopped

  # --- Optional: UI / external services ---

  tunnel:
    image: cloudflare/cloudflared:latest
    container_name: tunnel
    restart: unless-stopped
    command: tunnel run
    environment:
      - TUNNEL_TOKEN=${TUNNEL_TOKEN}

  jellyfin:
    image: lscr.io/linuxserver/jellyfin:latest
    container_name: jellyfin
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - TZ=${TZ}
    volumes:
      - ./jellyfin/library:/config
      - organized:/organized
    ports:
      - "8096:8096"
      - "8920:8920"
      - "7359:7359/udp"
      - "1900:1900/udp"
    restart: unless-stopped

  deemix:
    image: registry.gitlab.com/bockiii/deemix-docker
    container_name: deemix
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
      - UMASK_SET=022
    volumes:
      - input:/downloads
      - ./deemix_config:/config
    ports:
      - "6595:6595"
    restart: unless-stopped

  doublecommander:
    image: lscr.io/linuxserver/doublecommander:latest
    container_name: doublecommander
    environment:
      - PUID=${PUID}
      - PGID=${PGID}
    volumes:
      - input:/karaoke-mvp/input
      - output:/karaoke-mvp/output
      - stems:/karaoke-mvp/stems
      - queue:/karaoke-mvp/queue
      - metadata_json:/karaoke-mvp/metadata/json
      - organized:/karaoke-mvp/organized
      - ./models:/karaoke-mvp/models
      - splitter_tmp:/karaoke-mvp/splitter-tmp
      - ./doublecommander_config:/config
    ports:
      - "3000:3000"
    restart: unless-stopped

  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - ./alert.rules.yml:/etc/prometheus/alert.rules.yml:ro
    ports:
      - "9090:9090"
    restart: unless-stopped

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3001:3000"
    volumes:
      - ./grafana_data:/var/lib/grafana
    restart: unless-stopped

  alertmanager:
    image: prom/alertmanager:latest
    container_name: alertmanager
    volumes:
      - ./alertmanager.yml:/etc/alertmanager/alertmanager.yml:ro
      - ./telegram.tmpl:/etc/alertmanager/telegram.tmpl:ro
    ports:
      - "9093:9093"
    restart: unless-stopped

# --- Named Volumes (persist data) ---
volumes:
  input:
  queue:
  metadata_json:
  stems:
  output:
  organized:
  splitter_tmp:
  shared_utils:
    driver: local
    driver_opts:
      type: none
      device: ./shared
      o: bind
